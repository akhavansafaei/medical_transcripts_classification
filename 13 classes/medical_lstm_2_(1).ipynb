{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d9xxPe3YEi-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f6b5ce-dabd-4848-b4bd-58eefaacd46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the train and test CSV files\n",
        "train = pd.read_csv('/content/drive/My Drive/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/test.csv')\n",
        "train=train[['text','ptext','index','label']]\n",
        "test=test[['text','ptext','index','label']]\n",
        "# Extract features (X) and labels (y) for train and test datasets\n",
        "X_train = train[['text', 'ptext']]\n",
        "y_train = train['label']\n",
        "\n",
        "X_test = test[['text', 'ptext']]\n",
        "y_test = test['label']\n"
      ],
      "metadata": {
        "id": "jl6znokhF3DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have a DataFrame 'data' with a 'label_index' column containing label indices\n",
        "\n",
        "# Split the data into training and test sets with stratified sampling\n",
        "#X_training, X_validation, y_training, y_validation = train_test_split(\n",
        "#    train[['text','ptext','index']],  # Features (TF-IDF vectors)\n",
        "#    train[['label','index']],      # Target variable (label indices)\n",
        "#    test_size=0.2,\n",
        "#    stratify=train['label'],  # Ensure stratified sampling based on label indices\n",
        "#    random_state=48  # Set a random seed for reproducibility\n",
        "#)\n",
        "\n",
        "# Merge X_train and y_train into the train DataFrame based on 'index' column\n",
        "#training = X_training.merge(y_training )\n",
        "\n",
        "# Merge X_test and y_test into the test DataFrame based on 'index' column\n",
        "#valid = X_validation.merge(y_validation)\n",
        "\n",
        "# Now, the 'train' and 'test' DataFrames are merged based on the 'index' column\n",
        "#training.to_csv('/content/drive/MyDrive/training.csv')\n",
        "#valid.to_csv('/content/drive/MyDrive/validation.csv')\n"
      ],
      "metadata": {
        "id": "Q4qT8-uAW1NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming you have already renamed the \"medical_specialty\" column to \"label\"\n",
        "\n",
        "# Create a LabelEncoder instance\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder to your unique labels and transform the \"label\" column\n",
        "\n",
        "# Load the train and test CSV files\n",
        "train = pd.read_csv('/content/drive/My Drive/training.csv')\n",
        "valid=pd.read_csv('/content/drive/My Drive/validation.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/test.csv')\n",
        "# List of categories\n",
        "categories = [\n",
        "    \"Surgery\",\n",
        "    \"Consult - History and Phy.\",\n",
        "    \"Cardiovascular / Pulmonary\",\n",
        "    \"Orthopedic\",\n",
        "    \"Radiology\",\n",
        "    \"General Medicine\",\n",
        "    \"Gastroenterology\",\n",
        "    \"Neurology\",\n",
        "    \"SOAP / Chart / Progress Notes\",\n",
        "    \"Obstetrics / Gynecology\",\n",
        "    \"Urology\",\n",
        "    \"Discharge Summary\"\n",
        "]\n",
        "specialty_numbers=[38, 5, 3, 27, 33, 15, 14, 22, 35, 24, 39, 10]\n",
        "# Iterate through the 'label' column of train, test, and valid dataframes\n",
        "for df in [train, test, valid]:\n",
        "    df['label'] = df['label'].apply(lambda x: x if x in specialty_numbers else 40)\n",
        "    df['label'] = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "\n",
        "# Now, the 'label' column in train, test, and valid contains only values in 'categories' or 'others'\n",
        "\n",
        "train=train[['text','ptext','index','label']]\n",
        "valid=valid[['text','ptext','index','label']]\n",
        "test=test[['text','ptext','index','label']]\n",
        "# Extract features (X) and labels (y) for train and test datasets\n",
        "X_train = train[['text', 'ptext']]\n",
        "y_train = train['label']\n",
        "\n",
        "X_valid=valid[['text', 'ptext']]\n",
        "y_valid = valid['label']\n",
        "\n",
        "X_test = test[['text', 'ptext']]\n",
        "y_test = test['label']\n"
      ],
      "metadata": {
        "id": "D3QtFKnfYNUL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specialty_counts = test['label'].value_counts()\n",
        "(specialty_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYUyPiF2qSDX",
        "outputId": "b37f8303-9cb3-4ec8-b8b3-7db0aba95cb1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    218\n",
              "12    214\n",
              "1     103\n",
              "0      74\n",
              "7      71\n",
              "8      55\n",
              "4      52\n",
              "3      45\n",
              "5      45\n",
              "9      33\n",
              "6      31\n",
              "11     31\n",
              "2      22\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(specialty_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT8G_xzZpbUk",
        "outputId": "a926106f-6b9d-4b6b-8ac5-195e493221d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# without preproccessing"
      ],
      "metadata": {
        "id": "TrXKwu0_TXHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Combine all the sentences from the 'article1' and 'summary1' columns\n",
        "train_sentences = X_train['text'].tolist()\n",
        "# Convert the sentences to lists of words\n",
        "train_sentences = [sentence.split() for sentence in train_sentences]\n",
        "\n",
        "# Create a Word2Vec model\n",
        "model = Word2Vec(train_sentences, vector_size=300, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Train the model\n",
        "model.train(train_sentences, total_examples=model.corpus_count, epochs=30)\n",
        "\n",
        "# Save the model\n",
        "#model.save(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "yYohCYSpF3E4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bec0f3c-30fd-4e5b-f850-1299cf7ebf97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34970382, 44241360)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(model.wv.key_to_index)\n",
        "\n",
        "print(len(model.wv.key_to_index))"
      ],
      "metadata": {
        "id": "c2oVpDrIF3Iw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a5e55b-26da-4945-91cd-2aeeb4030597"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "oov_tok='<oov>'\n",
        "oov_token=oov_tok\n",
        "tokenizer = Tokenizer(oov_token=oov_tok)#,num_words = vocab_size)\n",
        "#tokenizer = Tokenizer(num_words = vocab_size)\n",
        "\n",
        "tokenizer.fit_on_texts(X_train['text'])\n",
        "print(len(list(tokenizer.word_index.keys())))\n"
      ],
      "metadata": {
        "id": "NclCh5fjF3K6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b21546-4ef9-4d65-f7a3-291cf6a32841"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['text_indices'] = tokenizer.texts_to_sequences(X_train['text'])\n",
        "sequences = tokenizer.texts_to_sequences(X_train['text'])\n",
        "\n",
        "word_index = tokenizer.word_index\n"
      ],
      "metadata": {
        "id": "pcA_dVlvF3OP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ded7939-9159-4f8e-f44d-1ca707edcce5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-bac10b2cb6b3>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train['text_indices'] = tokenizer.texts_to_sequences(X_train['text'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train['text'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCPF44nGqOS2",
        "outputId": "d5cf9b91-a688-44db-d9c1-15b00e066204"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1653"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd-KtPqaqX3e",
        "outputId": "192ff336-4328-4dc8-92d4-35c33102edc3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "278"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lengths = [len(text.split()) for text in X_train['text']]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(lengths, bins=50, edgecolor='black')\n",
        "plt.xlabel('Length')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Lengths in embedding_feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kmsz1fKJF3Qp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "d30108c7-8c1c-4a77-df5d-6f831a6a0fe7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the mean of lengths\n",
        "mean_length = np.mean(lengths)\n",
        "\n",
        "# Calculate the quartiles (25th, 50th, and 75th percentiles)\n",
        "quartiles = np.percentile(lengths, [25, 50, 75])\n",
        "\n",
        "print(\"Mean Length:\", mean_length)\n",
        "print(\"25th Percentile (1st Quartile):\", quartiles[0])\n",
        "print(\"50th Percentile (Median):\", quartiles[1])\n",
        "print(\"75th Percentile (3rd Quartile):\", quartiles[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdYkDWporlrM",
        "outputId": "20f2d7b5-d189-416e-f410-26afcc1da5c7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Length: 464.1838212149827\n",
            "25th Percentile (1st Quartile): 241.0\n",
            "50th Percentile (Median): 393.0\n",
            "75th Percentile (3rd Quartile): 614.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = model.wv\n",
        "vocab_size = len(word_vectors.key_to_index)\n",
        "num_words=len(word_vectors.key_to_index)\n",
        "\n",
        "embedding_dim = model.vector_size\n",
        "print(embedding_dim)\n"
      ],
      "metadata": {
        "id": "TmTYEZVWUDNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03582322-93e9-45db-b6b5-2d0a63f5e539"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#padding_type = 'post'  # Pad sequences at the end\n",
        "#truncating_type = 'post'  # Truncate sequences at the end\n",
        "#max_length = 200\n",
        "# Padding sequences\n",
        "#padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n"
      ],
      "metadata": {
        "id": "cICkhMe0UDLg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_test['text_indices'] = tokenizer.texts_to_sequences(X_test['text'])\n",
        "#test_sequences = tokenizer.texts_to_sequences(X_test['text'])\n",
        "#test_padded_sequences = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n"
      ],
      "metadata": {
        "id": "TfgGNRGTUDHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main model"
      ],
      "metadata": {
        "id": "XwY4EEZqvhFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional\n",
        "from keras.models import Model\n",
        "# encoder input model\n",
        "max_length = 512\n",
        "inputs = Input(shape=(max_length,))\n",
        "#encoder1 = Embedding(input_dim=num_words, output_dim=embedding_dim)(inputs)\n",
        "encoder1 = Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[word_vectors.vectors], trainable=False)(inputs)\n",
        "encoder2 = LSTM(128, return_sequences=True)(encoder1)  # Add return_sequences=True\n",
        "# Bidirectional LSTM layer\n",
        "encoder2_bilstm = Bidirectional(LSTM(64))(encoder2)\n",
        "\n",
        "#outputs= Dense(5, activation='softmax')\n",
        "# Define output layers for each sentiment column\n",
        "output_layers = []\n",
        "x=13\n",
        "output_layer1 = Dense(32, activation='relu')(encoder2_bilstm)\n",
        "#output_layer2 = Dense(16, activation='relu')(output_layer1)\n",
        "output_layer = Dense(x, activation='softmax')(output_layer1)\n",
        "#output_layer = Dense(x, activation='softmax', name=col)(encoder2_bilstm) #label_encoder.classes_.shape[0]\n",
        "output_layers.append(output_layer)\n",
        "\n",
        "# Tie it together\n",
        "model = Model(inputs=inputs, outputs=output_layers)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "l7IB1tPHUDFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92888b4e-b99a-4b1b-dc10-341bdebb461b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 512)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 512, 300)          19378200  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 512, 128)          219648    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               98816     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19701221 (75.15 MB)\n",
            "Trainable params: 323021 (1.23 MB)\n",
            "Non-trainable params: 19378200 (73.92 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r62D1zp2_iQp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ui-nRWppUDCZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# Convert your text data to sequences and pad them\n",
        "padding_type = 'post'  # Pad sequences at the end\n",
        "truncating_type = 'post'  # Truncate sequences at the end\n",
        "# Padding sequences\n",
        "# Assuming you have already defined a tokenizer\n",
        "input_column=\"text\"\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train[input_column])\n",
        "train_padded_sequences = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test[input_column])\n",
        "test_padded_sequences = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n",
        "valid_sequences = tokenizer.texts_to_sequences(X_valid[input_column])\n",
        "valid_padded_sequences = pad_sequences(valid_sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n"
      ],
      "metadata": {
        "id": "OfKphBUEUDAU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with the EarlyStopping callback\n",
        "history = model.fit(train_padded_sequences, y_train,\n",
        "                    epochs=100, batch_size=512, validation_data=(valid_padded_sequences, y_valid),#validation_split=0.20,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(test_padded_sequences, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "z3BnaY3FVHGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d737b40-c730-4a1c-9415-81dcd865a124"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 14s 447ms/step - loss: 2.4258 - accuracy: 0.2320 - val_loss: 2.2451 - val_accuracy: 0.3119\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 2s 239ms/step - loss: 2.1729 - accuracy: 0.3176 - val_loss: 2.1004 - val_accuracy: 0.3157\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 2s 241ms/step - loss: 2.0369 - accuracy: 0.3349 - val_loss: 2.0047 - val_accuracy: 0.3522\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 2s 243ms/step - loss: 1.9393 - accuracy: 0.3598 - val_loss: 1.9453 - val_accuracy: 0.3736\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 2s 246ms/step - loss: 1.8666 - accuracy: 0.3783 - val_loss: 1.8991 - val_accuracy: 0.3673\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 1.7939 - accuracy: 0.3941 - val_loss: 1.8654 - val_accuracy: 0.3547\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 1.7222 - accuracy: 0.4001 - val_loss: 1.8307 - val_accuracy: 0.3484\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 2s 244ms/step - loss: 1.6569 - accuracy: 0.4133 - val_loss: 1.8219 - val_accuracy: 0.3673\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 2s 242ms/step - loss: 1.5873 - accuracy: 0.4205 - val_loss: 1.8015 - val_accuracy: 0.3597\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 2s 228ms/step - loss: 1.5148 - accuracy: 0.4422 - val_loss: 1.8377 - val_accuracy: 0.3535\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 2s 228ms/step - loss: 1.4592 - accuracy: 0.4511 - val_loss: 1.8282 - val_accuracy: 0.3472\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 2s 229ms/step - loss: 1.4127 - accuracy: 0.4592 - val_loss: 1.8345 - val_accuracy: 0.3308\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 2s 229ms/step - loss: 1.3491 - accuracy: 0.4835 - val_loss: 1.8523 - val_accuracy: 0.3182\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 2s 252ms/step - loss: 1.2963 - accuracy: 0.4935 - val_loss: 1.9281 - val_accuracy: 0.2981\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 1.7891 - accuracy: 0.3531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "086JExD90Bu2",
        "outputId": "1f36f55f-6ef5-4927-bb06-7176c97408a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.7891067266464233, 0.3531187176704407]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions from the model\n",
        "test_probabilities = model.predict(test_padded_sequences)\n",
        "\n",
        "# Find the predicted class labels using argmax\n",
        "test_predictions = test_probabilities.argmax(axis=1)\n",
        "\n",
        "# Create a DataFrame with a single column for predictions\n",
        "test_predictions_df = pd.DataFrame({'predictions': test_predictions})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "test_predictions_df.to_csv('/content/drive/MyDrive/bilstm_r.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhyx__e2vk66",
        "outputId": "d98a39d6-9f28-48aa-d02e-5122c2097865"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 27ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# new model"
      ],
      "metadata": {
        "id": "v7SuPfx6vnak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional, Conv1D, GlobalMaxPooling1D, Dropout, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "import numpy as np\n",
        "\n",
        "# Define input shape and embedding layer as you did before\n",
        "max_length = 512\n",
        "\n",
        "inputs = Input(shape=(max_length,))\n",
        "embedding_layer = Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[word_vectors.vectors], trainable=False)(inputs)\n",
        "\n",
        "# Apply LSTM layer with L2 regularization\n",
        "lstm_layer = LSTM(512, return_sequences=True, kernel_regularizer=l2(0.01))(embedding_layer)\n",
        "\n",
        "# Convolutional layer with batch normalization\n",
        "conv1d_layer = Conv1D(filters=128, kernel_size=3, activation='relu')(lstm_layer)\n",
        "conv1d_layer = BatchNormalization()(conv1d_layer)\n",
        "\n",
        "# Global max pooling layer\n",
        "global_max_pooling = GlobalMaxPooling1D()(conv1d_layer)\n",
        "\n",
        "# Apply dropout after global max pooling\n",
        "dropout_rate = 0.5\n",
        "dropout_layer = Dropout(dropout_rate)(global_max_pooling)\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "bilstm_layer = Bidirectional(LSTM(256))(lstm_layer)\n",
        "\n",
        "# Define output layers for each sentiment column\n",
        "output_layers = []\n",
        "num_classes = 13  # Replace with the actual number of classes\n",
        "\n",
        "output_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(dropout_layer)\n",
        "output_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(output_layer1)\n",
        "output_layer = Dense(num_classes, activation='softmax')(output_layer2)\n",
        "output_layers.append(output_layer)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=output_layers)\n",
        "\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YU5ZPJk_20b",
        "outputId": "374a6d81-0e48-48e6-cf89-1611bc67e3e9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 512)]             0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 512, 300)          19378200  \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 512, 512)          1665024   \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 510, 128)          196736    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 510, 128)          512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Gl  (None, 128)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 13)                845       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21266085 (81.12 MB)\n",
            "Trainable params: 1887629 (7.20 MB)\n",
            "Non-trainable params: 19378456 (73.92 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cwmZ5GPS_2xe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True)\n",
        "\n",
        "# Train the model with the EarlyStopping callback\n",
        "history = model.fit(train_padded_sequences, y_train,\n",
        "                    epochs=100, batch_size=512, validation_data=(valid_padded_sequences, y_valid),#validation_split=0.20,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(test_padded_sequences, y_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45jeirNG_2vi",
        "outputId": "136cd39e-c807-4d77-c1a2-b25f5222a3f2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 16s 1s/step - loss: 11.7465 - accuracy: 0.1416 - val_loss: 9.8423 - val_accuracy: 0.0742\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 9.4716 - accuracy: 0.1970 - val_loss: 9.1139 - val_accuracy: 0.2164\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 8.8301 - accuracy: 0.2304 - val_loss: 8.5122 - val_accuracy: 0.2164\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 8.2649 - accuracy: 0.2751 - val_loss: 7.9229 - val_accuracy: 0.2164\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 7.6890 - accuracy: 0.2663 - val_loss: 7.3899 - val_accuracy: 0.2704\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 7.1822 - accuracy: 0.2606 - val_loss: 6.9121 - val_accuracy: 0.2340\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 6.6720 - accuracy: 0.2896 - val_loss: 6.4794 - val_accuracy: 0.2352\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 6.2399 - accuracy: 0.3078 - val_loss: 6.1035 - val_accuracy: 0.2340\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 5.8583 - accuracy: 0.3034 - val_loss: 5.7211 - val_accuracy: 0.2327\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 5.5449 - accuracy: 0.3072 - val_loss: 5.5467 - val_accuracy: 0.2252\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 5.2519 - accuracy: 0.3072 - val_loss: 5.1896 - val_accuracy: 0.2730\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.9852 - accuracy: 0.3113 - val_loss: 4.9714 - val_accuracy: 0.2528\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.7548 - accuracy: 0.3289 - val_loss: 4.6980 - val_accuracy: 0.3283\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.6278 - accuracy: 0.3207 - val_loss: 4.6055 - val_accuracy: 0.3258\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.4341 - accuracy: 0.3229 - val_loss: 4.4807 - val_accuracy: 0.2390\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.2877 - accuracy: 0.3163 - val_loss: 4.3470 - val_accuracy: 0.2440\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.1175 - accuracy: 0.3365 - val_loss: 4.2374 - val_accuracy: 0.2428\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.9800 - accuracy: 0.3223 - val_loss: 4.1193 - val_accuracy: 0.2591\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.8542 - accuracy: 0.3308 - val_loss: 3.9877 - val_accuracy: 0.2969\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.7410 - accuracy: 0.3082 - val_loss: 3.8965 - val_accuracy: 0.2994\n",
            "32/32 [==============================] - 1s 37ms/step - loss: 4.6908 - accuracy: 0.3310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPZKAXMv_2rq",
        "outputId": "95833abd-dede-46a5-de21-b373e4863cdd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.69083309173584, 0.3309859037399292]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNmAeYw2_2qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with preprocessing"
      ],
      "metadata": {
        "id": "pdchqlEbVvp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Combine all the sentences from the 'article1' and 'summary1' columns\n",
        "train_sentences = X_train['ptext'].tolist()\n",
        "# Convert the sentences to lists of words\n",
        "train_sentences = [sentence.split() for sentence in train_sentences]\n",
        "\n",
        "# Create a Word2Vec model\n",
        "model = Word2Vec(train_sentences, vector_size=300, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Train the model\n",
        "model.train(train_sentences, total_examples=model.corpus_count, epochs=30)\n",
        "\n",
        "# Save the model\n",
        "#model.save(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "wdqDeLOVVxAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c98c16-4d28-4db1-c6b1-6ce16b318bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26879771, 28152660)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(model.wv.key_to_index)\n",
        "\n",
        "print(len(model.wv.key_to_index))"
      ],
      "metadata": {
        "id": "H4eMotx6ZTLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14ea72d-ccee-440e-d796-4b335b0bc3ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "oov_tok='<oov>'\n",
        "oov_token=oov_tok\n",
        "tokenizer = Tokenizer(oov_token=oov_tok)#,num_words = vocab_size)\n",
        "#tokenizer = Tokenizer(num_words = vocab_size)\n",
        "\n",
        "tokenizer.fit_on_texts(X_train['ptext'])\n",
        "print(len(list(tokenizer.word_index.keys())))\n"
      ],
      "metadata": {
        "id": "WX4OqhllZTJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90ccaa5-6b7e-4f63-96c3-fd2b50a29c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['ptext_indices'] = tokenizer.texts_to_sequences(X_train['ptext'])\n",
        "sequences = tokenizer.texts_to_sequences(X_train['ptext'])\n",
        "\n",
        "word_index = tokenizer.word_index\n"
      ],
      "metadata": {
        "id": "YJxDA7NvZTFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f6a28f0-a5bd-47c0-c5cc-2d61d648c034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-129-514c3f2e3239>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train['ptext_indices'] = tokenizer.texts_to_sequences(X_train['ptext'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = model.wv\n",
        "vocab_size = len(word_vectors.key_to_index)\n",
        "num_words=len(word_vectors.key_to_index)\n",
        "\n",
        "embedding_dim = model.vector_size\n",
        "print(embedding_dim)\n"
      ],
      "metadata": {
        "id": "6IKuhJDcZTEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7166d256-67b6-4b48-aedc-cf1190aaf53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional, Conv1D, GlobalMaxPooling1D, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "# Define input shape and embedding layer as you did before\n",
        "max_length = 512\n",
        "inputs = Input(shape=(max_length,))\n",
        "\n",
        "# encoder1 = Embedding(input_dim=num_words, output_dim=embedding_dim)(inputs)\n",
        "encoder1 = Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[word_vectors.vectors], trainable=False)(inputs)\n",
        "encoder2 = LSTM(512, return_sequences=True)(encoder1)  # Add return_sequences=True\n",
        "\n",
        "# Convolutional layer\n",
        "conv1d_layer = Conv1D(filters=128, kernel_size=3, activation='relu')(encoder2)\n",
        "\n",
        "# Global max pooling layer\n",
        "global_max_pooling = GlobalMaxPooling1D()(conv1d_layer)\n",
        "\n",
        "# Apply dropout after the convolutional and LSTM layers\n",
        "dropout_rate = 0.5\n",
        "dropout_layer = Dropout(dropout_rate)(global_max_pooling)\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "encoder2_bilstm = Bidirectional(LSTM(256))(encoder2)\n",
        "\n",
        "# Define output layers for each sentiment column as you did before\n",
        "output_layers = []\n",
        "x = 13\n",
        "\n",
        "output_layer1 = Dense(128, activation='relu')(dropout_layer)\n",
        "output_layer2 = Dense(64, activation='relu')(output_layer1)\n",
        "output_layer = Dense(x, activation='softmax')(output_layer2)\n",
        "output_layers.append(output_layer)\n",
        "\n",
        "# Tie it all together\n",
        "model = Model(inputs=inputs, outputs=output_layers)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "kmAlV5pmZTAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7996c9eb-8166-4fb3-ecd3-78a0c6bed472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_26 (InputLayer)       [(None, 512)]             0         \n",
            "                                                                 \n",
            " embedding_24 (Embedding)    (None, 512, 300)          5782800   \n",
            "                                                                 \n",
            " lstm_33 (LSTM)              (None, 512, 512)          1665024   \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 510, 128)          196736    \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Gl  (None, 128)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 13)                845       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7670173 (29.26 MB)\n",
            "Trainable params: 1887373 (7.20 MB)\n",
            "Non-trainable params: 5782800 (22.06 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rl1qKY-CZS_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional, Conv1D, GlobalMaxPooling1D, Dropout, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "import numpy as np\n",
        "\n",
        "# Define input shape and embedding layer as you did before\n",
        "max_length = 512\n",
        "\n",
        "inputs = Input(shape=(max_length,))\n",
        "embedding_layer = Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[word_vectors.vectors], trainable=False)(inputs)\n",
        "\n",
        "# Apply LSTM layer with L2 regularization\n",
        "lstm_layer = LSTM(512, return_sequences=True, kernel_regularizer=l2(0.01))(embedding_layer)\n",
        "\n",
        "# Convolutional layer with batch normalization\n",
        "conv1d_layer = Conv1D(filters=128, kernel_size=3, activation='relu')(lstm_layer)\n",
        "conv1d_layer = BatchNormalization()(conv1d_layer)\n",
        "\n",
        "# Global max pooling layer\n",
        "global_max_pooling = GlobalMaxPooling1D()(conv1d_layer)\n",
        "\n",
        "# Apply dropout after global max pooling\n",
        "dropout_rate = 0.5\n",
        "dropout_layer = Dropout(dropout_rate)(global_max_pooling)\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "bilstm_layer = Bidirectional(LSTM(256))(lstm_layer)\n",
        "\n",
        "# Define output layers for each sentiment column\n",
        "output_layers = []\n",
        "num_classes = 13  # Replace with the actual number of classes\n",
        "\n",
        "output_layer1 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(dropout_layer)\n",
        "output_layer2 = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(output_layer1)\n",
        "output_layer = Dense(num_classes, activation='softmax')(output_layer2)\n",
        "output_layers.append(output_layer)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=output_layers)\n",
        "\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7src_m22Le1",
        "outputId": "b7a078ba-4090-4aba-dbec-229944cc3d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_29 (InputLayer)       [(None, 512)]             0         \n",
            "                                                                 \n",
            " embedding_27 (Embedding)    (None, 512, 300)          5782800   \n",
            "                                                                 \n",
            " lstm_35 (LSTM)              (None, 512, 512)          1665024   \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 510, 128)          196736    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 510, 128)          512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Gl  (None, 128)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 13)                845       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7670685 (29.26 MB)\n",
            "Trainable params: 1887629 (7.20 MB)\n",
            "Non-trainable params: 5783056 (22.06 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# Convert your text data to sequences and pad them\n",
        "padding_type = 'post'  # Pad sequences at the end\n",
        "truncating_type = 'post'  # Truncate sequences at the end\n",
        "# Padding sequences\n",
        "# Assuming you have already defined a tokenizer\n",
        "input_column=\"ptext\"\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train[input_column])\n",
        "train_padded_sequences = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test[input_column])\n",
        "test_padded_sequences = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n",
        "valid_sequences = tokenizer.texts_to_sequences(X_valid[input_column])\n",
        "valid_padded_sequences = pad_sequences(valid_sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n"
      ],
      "metadata": {
        "id": "21qq8X1IZS7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Define a learning rate schedule\n",
        "def lr_schedule(epoch):\n",
        "    initial_lr = 0.001\n",
        "    if epoch < 10:\n",
        "        return initial_lr\n",
        "    else:\n",
        "        return initial_lr * 0.1\n",
        "\n",
        "# Create a learning rate scheduler\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Compile the model with the Adam optimizer and the scheduler\n",
        "optimizer = Adam(learning_rate=0.001)  # You can adjust the initial learning rate\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "pXEPsHG04O6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with the EarlyStopping callback\n",
        "history = model.fit(train_padded_sequences, y_train,\n",
        "                    epochs=50, batch_size=512, validation_data=(valid_padded_sequences, y_valid),#validation_split=0.20,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(test_padded_sequences, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "1DdidV6kZS6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aaafe15-49ad-4cb4-a1f2-9db676629808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 54s 8s/step - loss: 10.8113 - accuracy: 0.1564 - val_loss: 9.3801 - val_accuracy: 0.0969\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 9.1915 - accuracy: 0.2169 - val_loss: 8.7202 - val_accuracy: 0.1572\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 8.3875 - accuracy: 0.2496 - val_loss: 7.9997 - val_accuracy: 0.2767\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 7.6880 - accuracy: 0.2745 - val_loss: 7.3351 - val_accuracy: 0.2956\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 7.0249 - accuracy: 0.2776 - val_loss: 6.7007 - val_accuracy: 0.3396\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 6.4181 - accuracy: 0.3044 - val_loss: 6.0747 - val_accuracy: 0.3220\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 5.9513 - accuracy: 0.2940 - val_loss: 5.6697 - val_accuracy: 0.3145\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 5.5324 - accuracy: 0.3094 - val_loss: 5.6916 - val_accuracy: 0.2050\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 7s 1s/step - loss: 5.2173 - accuracy: 0.3100 - val_loss: 5.2926 - val_accuracy: 0.2302\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.9225 - accuracy: 0.3063 - val_loss: 4.8810 - val_accuracy: 0.2843\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 7s 1s/step - loss: 4.7096 - accuracy: 0.3053 - val_loss: 4.6974 - val_accuracy: 0.2478\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.4521 - accuracy: 0.3097 - val_loss: 4.4602 - val_accuracy: 0.2805\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.2837 - accuracy: 0.3094 - val_loss: 4.3858 - val_accuracy: 0.2201\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.1123 - accuracy: 0.3160 - val_loss: 4.1992 - val_accuracy: 0.2403\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.9502 - accuracy: 0.3396 - val_loss: 4.0873 - val_accuracy: 0.2491\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.8077 - accuracy: 0.3377 - val_loss: 4.0054 - val_accuracy: 0.2277\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.6855 - accuracy: 0.3292 - val_loss: 3.8619 - val_accuracy: 0.3283\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.5705 - accuracy: 0.3551 - val_loss: 3.8455 - val_accuracy: 0.2390\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.4394 - accuracy: 0.3444 - val_loss: 3.6764 - val_accuracy: 0.2943\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.3240 - accuracy: 0.3632 - val_loss: 3.6557 - val_accuracy: 0.2654\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.2188 - accuracy: 0.3692 - val_loss: 3.5280 - val_accuracy: 0.2654\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.1332 - accuracy: 0.3676 - val_loss: 3.4254 - val_accuracy: 0.2679\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 3.0574 - accuracy: 0.3636 - val_loss: 3.4588 - val_accuracy: 0.2403\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.9831 - accuracy: 0.3667 - val_loss: 3.4439 - val_accuracy: 0.2340\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.8842 - accuracy: 0.3683 - val_loss: 3.3354 - val_accuracy: 0.2478\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.8247 - accuracy: 0.3787 - val_loss: 3.2834 - val_accuracy: 0.2478\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.7637 - accuracy: 0.3752 - val_loss: 3.2068 - val_accuracy: 0.3094\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.7165 - accuracy: 0.3796 - val_loss: 3.1229 - val_accuracy: 0.2704\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.6898 - accuracy: 0.3654 - val_loss: 3.1198 - val_accuracy: 0.2780\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.5834 - accuracy: 0.4001 - val_loss: 3.1895 - val_accuracy: 0.2415\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.5876 - accuracy: 0.3878 - val_loss: 3.0230 - val_accuracy: 0.2843\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.5280 - accuracy: 0.3897 - val_loss: 2.9623 - val_accuracy: 0.3044\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.4556 - accuracy: 0.3938 - val_loss: 3.0099 - val_accuracy: 0.2692\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.4193 - accuracy: 0.4142 - val_loss: 2.8794 - val_accuracy: 0.3132\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.3990 - accuracy: 0.4130 - val_loss: 2.8996 - val_accuracy: 0.3472\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.3342 - accuracy: 0.4171 - val_loss: 2.8415 - val_accuracy: 0.3384\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.2874 - accuracy: 0.4196 - val_loss: 2.8187 - val_accuracy: 0.3082\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.2446 - accuracy: 0.4372 - val_loss: 2.7893 - val_accuracy: 0.2566\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.2229 - accuracy: 0.4136 - val_loss: 2.7375 - val_accuracy: 0.2843\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.2099 - accuracy: 0.4215 - val_loss: 2.7486 - val_accuracy: 0.2918\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.1528 - accuracy: 0.4252 - val_loss: 2.6594 - val_accuracy: 0.2742\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.1279 - accuracy: 0.4419 - val_loss: 2.6919 - val_accuracy: 0.2931\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0719 - accuracy: 0.4369 - val_loss: 2.6240 - val_accuracy: 0.2780\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0175 - accuracy: 0.4573 - val_loss: 2.5943 - val_accuracy: 0.3031\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0154 - accuracy: 0.4520 - val_loss: 2.6244 - val_accuracy: 0.2981\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9904 - accuracy: 0.4473 - val_loss: 2.6421 - val_accuracy: 0.2881\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9606 - accuracy: 0.4533 - val_loss: 2.5271 - val_accuracy: 0.3082\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9608 - accuracy: 0.4435 - val_loss: 2.5022 - val_accuracy: 0.3006\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9276 - accuracy: 0.4586 - val_loss: 2.5470 - val_accuracy: 0.2868\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9079 - accuracy: 0.4696 - val_loss: 2.4419 - val_accuracy: 0.2843\n",
            "32/32 [==============================] - 1s 35ms/step - loss: 2.4933 - accuracy: 0.2656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with the EarlyStopping callback\n",
        "history = model.fit(train_padded_sequences, y_train,\n",
        "                    epochs=50, batch_size=512, validation_data=(valid_padded_sequences, y_valid),#validation_split=0.20,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(test_padded_sequences, y_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlfrMc4d6MB3",
        "outputId": "d4d8a539-09f5-4944-8918-fadc43541759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8966 - accuracy: 0.4570 - val_loss: 2.4318 - val_accuracy: 0.3006\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8924 - accuracy: 0.4473 - val_loss: 2.4703 - val_accuracy: 0.2579\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8495 - accuracy: 0.4577 - val_loss: 2.4016 - val_accuracy: 0.2767\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8304 - accuracy: 0.4640 - val_loss: 2.3688 - val_accuracy: 0.2918\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.8057 - accuracy: 0.4611 - val_loss: 2.3340 - val_accuracy: 0.2830\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7769 - accuracy: 0.4759 - val_loss: 2.3247 - val_accuracy: 0.2780\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7620 - accuracy: 0.4797 - val_loss: 2.2946 - val_accuracy: 0.2969\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7462 - accuracy: 0.4847 - val_loss: 2.2928 - val_accuracy: 0.2818\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7388 - accuracy: 0.4819 - val_loss: 2.2196 - val_accuracy: 0.2855\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6781 - accuracy: 0.4904 - val_loss: 2.3167 - val_accuracy: 0.2516\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6718 - accuracy: 0.4882 - val_loss: 2.2063 - val_accuracy: 0.3057\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6631 - accuracy: 0.4898 - val_loss: 2.2243 - val_accuracy: 0.2943\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6461 - accuracy: 0.4935 - val_loss: 2.2269 - val_accuracy: 0.2855\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6239 - accuracy: 0.5080 - val_loss: 2.2061 - val_accuracy: 0.2881\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6004 - accuracy: 0.4989 - val_loss: 2.2294 - val_accuracy: 0.2818\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5949 - accuracy: 0.5087 - val_loss: 2.1742 - val_accuracy: 0.2969\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6124 - accuracy: 0.4929 - val_loss: 2.1953 - val_accuracy: 0.3082\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6204 - accuracy: 0.4976 - val_loss: 2.1619 - val_accuracy: 0.2692\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5998 - accuracy: 0.4998 - val_loss: 2.1438 - val_accuracy: 0.2792\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5866 - accuracy: 0.4895 - val_loss: 2.1304 - val_accuracy: 0.2679\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5745 - accuracy: 0.5074 - val_loss: 2.1239 - val_accuracy: 0.2704\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5533 - accuracy: 0.5137 - val_loss: 2.1469 - val_accuracy: 0.2981\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5380 - accuracy: 0.5087 - val_loss: 2.1722 - val_accuracy: 0.2780\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5232 - accuracy: 0.5266 - val_loss: 2.1519 - val_accuracy: 0.2654\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5205 - accuracy: 0.5087 - val_loss: 2.0856 - val_accuracy: 0.2516\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4862 - accuracy: 0.5212 - val_loss: 2.1116 - val_accuracy: 0.2516\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4935 - accuracy: 0.5131 - val_loss: 2.1525 - val_accuracy: 0.2591\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4647 - accuracy: 0.5225 - val_loss: 2.1086 - val_accuracy: 0.2453\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4712 - accuracy: 0.5241 - val_loss: 2.0840 - val_accuracy: 0.2629\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4406 - accuracy: 0.5357 - val_loss: 2.1074 - val_accuracy: 0.2692\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4435 - accuracy: 0.5105 - val_loss: 2.1453 - val_accuracy: 0.2390\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4196 - accuracy: 0.5266 - val_loss: 2.0954 - val_accuracy: 0.2566\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4281 - accuracy: 0.5288 - val_loss: 2.0981 - val_accuracy: 0.2591\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4157 - accuracy: 0.5433 - val_loss: 2.0911 - val_accuracy: 0.2302\n",
            "32/32 [==============================] - 1s 35ms/step - loss: 2.1239 - accuracy: 0.2555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-eUihn3xe1U",
        "outputId": "0b6b6210-81f5-4d88-ad6a-37d7d44126fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.7601737976074219, 0.3541247546672821]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main model with preprocessing"
      ],
      "metadata": {
        "id": "TsPz1EBuvwxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense, Bidirectional\n",
        "from keras.models import Model\n",
        "# encoder input model\n",
        "max_length = 512\n",
        "inputs = Input(shape=(max_length,))\n",
        "#encoder1 = Embedding(input_dim=num_words, output_dim=embedding_dim)(inputs)\n",
        "encoder1 = Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[word_vectors.vectors], trainable=False)(inputs)\n",
        "encoder2 = LSTM(128, return_sequences=True)(encoder1)  # Add return_sequences=True\n",
        "# Bidirectional LSTM layer\n",
        "encoder2_bilstm = Bidirectional(LSTM(64))(encoder2)\n",
        "\n",
        "#outputs= Dense(5, activation='softmax')\n",
        "# Define output layers for each sentiment column\n",
        "output_layers = []\n",
        "x=13\n",
        "output_layer1 = Dense(32, activation='relu')(encoder2_bilstm)\n",
        "#output_layer2 = Dense(16, activation='relu')(output_layer1)\n",
        "output_layer = Dense(x, activation='softmax')(output_layer1)\n",
        "#output_layer = Dense(x, activation='softmax', name=col)(encoder2_bilstm) #label_encoder.classes_.shape[0]\n",
        "output_layers.append(output_layer)\n",
        "\n",
        "# Tie it together\n",
        "model = Model(inputs=inputs, outputs=output_layers)\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# Convert your text data to sequences and pad them\n",
        "padding_type = 'post'  # Pad sequences at the end\n",
        "truncating_type = 'post'  # Truncate sequences at the end\n",
        "# Padding sequences\n",
        "# Assuming you have already defined a tokenizer\n",
        "input_column=\"ptext\"\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train[input_column])\n",
        "train_padded_sequences = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test[input_column])\n",
        "test_padded_sequences = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n",
        "valid_sequences = tokenizer.texts_to_sequences(X_valid[input_column])\n",
        "valid_padded_sequences = pad_sequences(valid_sequences, maxlen=max_length, padding=padding_type, truncating=truncating_type)\n",
        "\n",
        "# Train the model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with the EarlyStopping callback\n",
        "history = model.fit(train_padded_sequences, y_train,\n",
        "                    epochs=100, batch_size=512, validation_data=(valid_padded_sequences, y_valid),#validation_split=0.20,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(test_padded_sequences, y_test)\n",
        "\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65fcyfFGAsVh",
        "outputId": "2853bd5c-fb52-4101-8d01-fefe752d3181"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 512)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 512, 300)          19378200  \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 512, 128)          219648    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 128)               98816     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19701221 (75.15 MB)\n",
            "Trainable params: 323021 (1.23 MB)\n",
            "Non-trainable params: 19378200 (73.92 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7/7 [==============================] - 9s 445ms/step - loss: 2.3591 - accuracy: 0.2345 - val_loss: 2.1823 - val_accuracy: 0.3245\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 2s 249ms/step - loss: 2.1353 - accuracy: 0.3211 - val_loss: 2.0587 - val_accuracy: 0.3283\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 2s 253ms/step - loss: 2.0151 - accuracy: 0.3374 - val_loss: 1.9844 - val_accuracy: 0.3597\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 2s 230ms/step - loss: 1.9351 - accuracy: 0.3544 - val_loss: 1.9198 - val_accuracy: 0.3535\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 2s 248ms/step - loss: 1.8528 - accuracy: 0.3692 - val_loss: 1.8657 - val_accuracy: 0.3698\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 2s 232ms/step - loss: 1.7733 - accuracy: 0.3931 - val_loss: 1.8264 - val_accuracy: 0.3509\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 2s 247ms/step - loss: 1.6974 - accuracy: 0.4212 - val_loss: 1.7912 - val_accuracy: 0.3899\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 1.6169 - accuracy: 0.4262 - val_loss: 1.7528 - val_accuracy: 0.3585\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 1.5426 - accuracy: 0.4441 - val_loss: 1.7398 - val_accuracy: 0.3648\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 2s 231ms/step - loss: 1.4808 - accuracy: 0.4583 - val_loss: 1.7413 - val_accuracy: 0.3459\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 2s 240ms/step - loss: 1.4114 - accuracy: 0.4699 - val_loss: 1.7474 - val_accuracy: 0.3560\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 2s 260ms/step - loss: 1.3558 - accuracy: 0.4794 - val_loss: 1.7965 - val_accuracy: 0.3346\n",
            "32/32 [==============================] - 1s 24ms/step - loss: 1.8048 - accuracy: 0.3652\n",
            "[1.8048112392425537, 0.36519116163253784]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions from the model\n",
        "test_probabilities = model.predict(test_padded_sequences)\n",
        "\n",
        "# Find the predicted class labels using argmax\n",
        "test_predictions = test_probabilities.argmax(axis=1)\n",
        "test_predictions"
      ],
      "metadata": {
        "id": "_etbnL2Zvzx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oHcgdZqxk-K"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a DataFrame with a single column for predictions\n",
        "test_predictions_df = pd.DataFrame({'predictions': test_predictions})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "test_predictions_df.to_csv('/content/drive/MyDrive/bilstm_pp_r.csv', index=False)\n"
      ],
      "metadata": {
        "id": "YADvRCkYxkof"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here"
      ],
      "metadata": {
        "id": "RhtkNvubDgBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# another"
      ],
      "metadata": {
        "id": "pAr9CGRjrkRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv1D, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define your input shape and other parameters\n",
        "max_length = 512\n",
        "num_classes = 13\n",
        "\n",
        "# Encoder input model\n",
        "inputs = Input(shape=(max_length,))\n",
        "encoder1 = Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[word_vectors.vectors], trainable=False)(inputs)\n",
        "\n",
        "# Add a Conv1D layer\n",
        "conv_layer = Conv1D(filters=1024, kernel_size=3, activation='relu')(encoder1)\n",
        "\n",
        "output_layer1 = Dense(512, activation='relu')(conv_layer)\n",
        "output_layer2 = Dropout(0.5)(output_layer1)\n",
        "flatten = Flatten()(output_layer2)\n",
        "output_layer3 = Dense(128, activation='relu')(flatten)\n",
        "output_layer = Dense(num_classes, activation='softmax')(output_layer3)\n",
        "\n",
        "# Tie it together\n",
        "model = Model(inputs=inputs, outputs=output_layer)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "gdezgEROrlm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98158f83-dbb1-4d1f-bf62-af41fc987e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_22 (InputLayer)       [(None, 512)]             0         \n",
            "                                                                 \n",
            " embedding_20 (Embedding)    (None, 512, 300)          5782800   \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 510, 1024)         922624    \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 510, 512)          524800    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 510, 512)          0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 261120)            0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 128)               33423488  \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 13)                1677      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40655389 (155.09 MB)\n",
            "Trainable params: 34872589 (133.03 MB)\n",
            "Non-trainable params: 5782800 (22.06 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0rj9iKCFwgGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with the EarlyStopping callback\n",
        "history = model.fit(train_padded_sequences, y_train,\n",
        "                    epochs=50, batch_size=512, validation_data=(valid_padded_sequences, y_valid),#validation_split=0.20,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(test_padded_sequences, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "srRbsAG7wgCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c08ab3b-2710-410c-8756-c01554f51b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 14s 1s/step - loss: 50.4583 - accuracy: 0.1627 - val_loss: 2.5463 - val_accuracy: 0.1044\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 4s 559ms/step - loss: 2.5534 - accuracy: 0.1036 - val_loss: 2.5479 - val_accuracy: 0.1019\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 4s 623ms/step - loss: 2.5330 - accuracy: 0.0935 - val_loss: 2.4948 - val_accuracy: 0.1233\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 4s 626ms/step - loss: 2.4518 - accuracy: 0.1857 - val_loss: 2.4043 - val_accuracy: 0.2088\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 4s 606ms/step - loss: 2.3849 - accuracy: 0.2210 - val_loss: 2.3645 - val_accuracy: 0.2088\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 4s 556ms/step - loss: 2.3549 - accuracy: 0.2254 - val_loss: 2.3498 - val_accuracy: 0.1950\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 4s 626ms/step - loss: 2.3457 - accuracy: 0.2288 - val_loss: 2.3387 - val_accuracy: 0.2151\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 4s 552ms/step - loss: 2.3294 - accuracy: 0.2304 - val_loss: 2.3417 - val_accuracy: 0.1950\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 4s 599ms/step - loss: 2.3330 - accuracy: 0.2370 - val_loss: 2.3340 - val_accuracy: 0.2138\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 4s 594ms/step - loss: 2.3197 - accuracy: 0.2380 - val_loss: 2.3298 - val_accuracy: 0.2013\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 4s 572ms/step - loss: 2.3165 - accuracy: 0.2241 - val_loss: 2.3281 - val_accuracy: 0.2164\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 4s 627ms/step - loss: 2.3190 - accuracy: 0.2288 - val_loss: 2.3297 - val_accuracy: 0.2214\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 4s 542ms/step - loss: 2.3159 - accuracy: 0.2288 - val_loss: 2.3437 - val_accuracy: 0.2025\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 4s 540ms/step - loss: 2.3243 - accuracy: 0.2314 - val_loss: 2.3256 - val_accuracy: 0.2176\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 4s 542ms/step - loss: 2.3242 - accuracy: 0.2304 - val_loss: 2.3223 - val_accuracy: 0.2025\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 4s 587ms/step - loss: 2.3087 - accuracy: 0.2288 - val_loss: 2.3266 - val_accuracy: 0.2113\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 4s 565ms/step - loss: 2.3106 - accuracy: 0.2251 - val_loss: 2.3260 - val_accuracy: 0.2239\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 4s 541ms/step - loss: 2.3089 - accuracy: 0.2298 - val_loss: 2.3240 - val_accuracy: 0.2239\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 4s 545ms/step - loss: 2.3075 - accuracy: 0.2345 - val_loss: 2.3370 - val_accuracy: 0.2226\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 4s 542ms/step - loss: 2.3215 - accuracy: 0.2304 - val_loss: 2.3166 - val_accuracy: 0.2050\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 4s 542ms/step - loss: 2.3067 - accuracy: 0.2310 - val_loss: 2.3129 - val_accuracy: 0.2201\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 4s 630ms/step - loss: 2.3063 - accuracy: 0.2147 - val_loss: 2.3136 - val_accuracy: 0.2050\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 2.3149 - accuracy: 0.2113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# new columns"
      ],
      "metadata": {
        "id": "ssDeOOnjwpUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "vectorizer=CountVectorizer(analyzer='word')\n",
        "feature_space=vectorizer.fit_transform(list(train['text']))\n",
        "count_vect_df = pd.DataFrame(feature_space.todense())\n",
        "new_df=pd.concat([train, count_vect_df], axis=1)\n",
        "new_df.head()"
      ],
      "metadata": {
        "id": "HZC-N6T8wgBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "baa6d5be-3561-4f69-ef4e-6b41c4a2c0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  TITLE OF PROCEDURE,Creation of AV fistula, lef...   \n",
              "1  PREOPERATIVE DIAGNOSIS: , Tailor's bunion, rig...   \n",
              "2  PROCEDURE: , Placement of left ventriculostomy...   \n",
              "3  SUBJECTIVE:  ,The patient seen and examined fe...   \n",
              "4  HISTORY OF PRESENT ILLNESS:,  This is a 55-yea...   \n",
              "\n",
              "                                               ptext  index  label  0  1  2  \\\n",
              "0  title procedure creation av fistula left wrist...   1176     10  0  0  0   \n",
              "1  preoperative diagnosis tailor bunion right foo...    997     10  0  0  0   \n",
              "2  procedure placement left ventriculostomy via t...   2738      5  0  0  0   \n",
              "3  subjective patient seen examined feel better t...   1409      9  0  1  0   \n",
              "4  history present illness 55 year old female his...   3758     12  0  0  0   \n",
              "\n",
              "   3  4  5  ...  21112  21113  21114  21115  21116  21117  21118  21119  \\\n",
              "0  0  0  0  ...      0      0      0      0      0      0      0      0   \n",
              "1  0  0  0  ...      0      0      0      0      0      0      0      0   \n",
              "2  0  0  0  ...      0      0      0      0      0      0      0      0   \n",
              "3  0  0  0  ...      0      0      0      0      0      0      0      0   \n",
              "4  0  0  0  ...      0      0      0      0      0      0      0      0   \n",
              "\n",
              "   21120  21121  \n",
              "0      0      0  \n",
              "1      0      0  \n",
              "2      0      0  \n",
              "3      0      0  \n",
              "4      0      0  \n",
              "\n",
              "[5 rows x 21126 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25e413bf-9d81-402d-b12e-cb6461cb8775\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>ptext</th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>...</th>\n",
              "      <th>21112</th>\n",
              "      <th>21113</th>\n",
              "      <th>21114</th>\n",
              "      <th>21115</th>\n",
              "      <th>21116</th>\n",
              "      <th>21117</th>\n",
              "      <th>21118</th>\n",
              "      <th>21119</th>\n",
              "      <th>21120</th>\n",
              "      <th>21121</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TITLE OF PROCEDURE,Creation of AV fistula, lef...</td>\n",
              "      <td>title procedure creation av fistula left wrist...</td>\n",
              "      <td>1176</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PREOPERATIVE DIAGNOSIS: , Tailor's bunion, rig...</td>\n",
              "      <td>preoperative diagnosis tailor bunion right foo...</td>\n",
              "      <td>997</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PROCEDURE: , Placement of left ventriculostomy...</td>\n",
              "      <td>procedure placement left ventriculostomy via t...</td>\n",
              "      <td>2738</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SUBJECTIVE:  ,The patient seen and examined fe...</td>\n",
              "      <td>subjective patient seen examined feel better t...</td>\n",
              "      <td>1409</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HISTORY OF PRESENT ILLNESS:,  This is a 55-yea...</td>\n",
              "      <td>history present illness 55 year old female his...</td>\n",
              "      <td>3758</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21126 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25e413bf-9d81-402d-b12e-cb6461cb8775')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25e413bf-9d81-402d-b12e-cb6461cb8775 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25e413bf-9d81-402d-b12e-cb6461cb8775');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9f59f09-8ab7-455a-a262-c0a1e6e50774\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9f59f09-8ab7-455a-a262-c0a1e6e50774')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9f59f09-8ab7-455a-a262-c0a1e6e50774 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3Ww36j60AZV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}